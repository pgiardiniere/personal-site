---
title: "Deep Learning for Computer Vision series is up!"
date: "2023-09-01"
updated: "2023-09-01"
categories:
  - "archives"
  - "cs231n"
  - "Deep Learning"
  - "computer-vision"
excerpt: An announcement that the computer vision content has all been posted, together with some reflection on the work generally and ____.
---

Definitely there are signs these are my first steps into machine learning / computer vision spaces. I left many free-answser questions blank that today I'd consider total freebies (e.g. yes, Sigmoid is worse for gradient flow than ReLU/Leaky-ReLU). 

I did this all before starting the graduate program, which would fill some of the gaps.

This is an excellent catalog of the my journey to getting current with computer vision literature in 2021, and I felt it shoud be published.

Do wish I had more time with Transformers though.


1. Wish I had some better 

The style of the posts reads a little like a work log. Which was part of their purpose at the time, but reflecting on it now, it would have been nice if I had left a little more direct reflection on my thought process in prose. 

That said, reviewing the links I left together with the code and course materials does leave enough on the breadcrumb trail that it should be parseable even to new readers.


2. Notation just everywhere, all over the place

It's the nature of the beast to get sucked into the vortex of math notations, but holy moly there sure is a lot of complexity being piled into these variables.


3. 

